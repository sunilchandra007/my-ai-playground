## ðŸ§  Vector Search
- Helps to find semantically similar items (like documents, images, or queries) by comparing **embedding vectors**.
---

### ðŸ”¹ 1. Input Stage
- **Input Document**: This could be a document, sentence, or query.
- **Query Text**: Example: "cloud threat"

---

### ðŸ”¹ 2. Tokenizer
- Splits the input into tokens (subwords or words)
- Maps each token to a **token ID** using a vocabulary
- Example: "cloud threat" â†’ [1234, 5678]

---

### ðŸ”¹ 3. Embedding Model
- Converts token IDs into **dense vectors**
- Capture the **context** and **semantic meaning** with transformer layer
- Outputs either:
  - Per-token embeddings
  - A single pooled embedding (e.g., fixed-size vector with 1024-dimensional)

---

### ðŸ”¹ 4. Vector Database
- Stores all document embeddings.

### ðŸ”¹ 5. Search Query
- New input is tokenized and embedded
- Compared to stored vectors using metrics like **cosine similarity**.
- Returns the **Top Matching Results** based on semantic closeness.

---

## ðŸŒ Mermaid Diagram

```mermaid
flowchart TD
    subgraph Input["ðŸ”¹ Input Stage"]
        A[ðŸ“ Document]
        G[ðŸ” Query Text]
    end

    subgraph Tokenization["ðŸ”¹ Tokenization"]
        B[ðŸ§© Tokenizer]
        H[ðŸ§© Tokenizer]
        C[ðŸ”¢ Token IDs]
        I[ðŸ”¢ Query Token IDs]
    end

    subgraph Embedding["ðŸ”¹ Embedding Model"]
        D[ðŸ“¦ Embedding Model]
        J[ðŸ“¦ Embedding Model]
        E[ðŸ“ˆ Embedding Vector]
        K[ðŸ“ˆ Query Embedding]
    end

    subgraph Search["ðŸ”¹ Vector Search"]
        F[ðŸ—ƒï¸ Vector Database]
        L[ðŸ“Š Similarity Search]
        M[ðŸ“„ Top Matching Results]
    end

    A --> B --> C --> D --> E --> F
    G --> H --> I --> J --> K --> L
    F --> L --> M
